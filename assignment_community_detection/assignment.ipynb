{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment — Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from zlib import adler32\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we try to detect communities in Les Miserables graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from(nx.les_miserables_graph().edges)\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw_networkx_nodes(G, pos, node_color='white', edgecolors='black', node_size=100)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Girvan Newman algorithm (0.8 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply Girvan Newman algorithm with edge betweenness. The idea is we cut edges with highest betweenness until the graph becomes disconnected. Use `nx.algorithms.community.girvan_newman` to find communities.\n",
    "\n",
    "Write a function `edge_betweenness` that takes a graph and the number of divisions and returns np.array of (integer) labels of nodes in each iteration. The shape of the output is [n, m] where n is a number of iteration and m is a number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78ae0c3a1e46a3805215acf726f2bfc0",
     "grade": false,
     "grade_id": "cell-d871f77dcf06fa15",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def edge_betweenness(G, n):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe30c29f3d819175f455f51821d2bc48",
     "grade": true,
     "grade_id": "cell-8dd9a36b0d20c57d",
     "locked": true,
     "points": 0.8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "labels = edge_betweenness(G, 6)\n",
    "assert labels.shape == (6, 77)\n",
    "assert np.unique(labels[0]).shape == (2,)\n",
    "assert np.unique(labels[0]).shape[0] < np.unique(labels[1]).shape[0] < np.unique(labels[5]).shape[0]\n",
    "assert labels[5][22] == labels[5][23]\n",
    "assert labels[5][31] == labels[5][34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw Girvan Newman algorithm step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7*2, 7*3))\n",
    "colors = edge_betweenness(G, 6)\n",
    "for i in range(colors.shape[0]):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, \n",
    "        pos,\n",
    "        cmap=plt.cm.rainbow,\n",
    "        node_color=colors[i], \n",
    "        node_size=100, \n",
    "        edgecolors='black'\n",
    "    )\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "    plt.title('Edge betweenness, {} communities'.format(i+2))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Modularity (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modularity helps to decide when to stop splitting the graph. The large modularity, the better partitioning. Let us see how modularity changes during division.\n",
    "\n",
    "Write a function `edge_betw_modularity` that takes a graph, number of iterations of Girvan Newman algorithm and returns a np.array with modularity after each iteration. Use `nx.algorithms.community.modularity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17263e09aceb2cdcd822a6ba9d1e8a83",
     "grade": false,
     "grade_id": "cell-9f7fb2b1efbb7ba5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def edge_betw_modularity(G, n):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0affd7b014dab1db467ae83163fd0a7f",
     "grade": true,
     "grade_id": "cell-8701bf83b9020f57",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_iterations = 20\n",
    "modularity = edge_betw_modularity(G, n_iterations)\n",
    "assert modularity.shape == (n_iterations, )\n",
    "assert round(modularity[0], 4) == 0.0746\n",
    "assert round(modularity[7], 4) == 0.4519"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw dependency between a number of iteration and modularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(np.arange(n_iterations)+2, modularity)\n",
    "best_n = np.argmax(modularity) + 2\n",
    "label = 'number of communities with max modularity {:.2f}'.format(max(modularity))\n",
    "plt.plot(\n",
    "    [best_n, best_n], [min(modularity), max(modularity)], \n",
    "    'k--', c='tab:red', \n",
    "    label=label\n",
    ")\n",
    "plt.ylabel('Modularity score')\n",
    "plt.xlabel('Number of communities')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim((modularity.min(), 0.6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Eigenvalues of graph Laplacian (0.8 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few auxiliary methods for graph generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb7b8364134cf37ea83a646413ede86b",
     "grade": false,
     "grade_id": "cell-61366d4f5cae4691",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ring_lattice(n, k):\n",
    "    G = nx.Graph()\n",
    "    nodes = list(range(n))\n",
    "    for i in range(1, int(k/2 + 1)):\n",
    "        targets = nodes[i:] + nodes[:i]\n",
    "        G.add_edges_from(zip(nodes, targets))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f817361f4028724aeb63ee45720b069",
     "grade": false,
     "grade_id": "cell-1ed7d5679e35118f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pair_graph(n):\n",
    "    G = nx.disjoint_union(nx.complete_graph(n), nx.complete_graph(n))\n",
    "    G.add_edge(0, n)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ebc3e27a111b4c5dec8e08be526cb3d",
     "grade": false,
     "grade_id": "cell-c3199879fe237653",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def triple_graph(n):\n",
    "    G = nx.disjoint_union_all(\n",
    "        [nx.complete_graph(n), nx.complete_graph(n), nx.complete_graph(n)]\n",
    "    )\n",
    "    G.add_edge(0, n)\n",
    "    G.add_edge(n, n*2)\n",
    "    G.add_edge(n*2, 0)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Laplacian is\n",
    "\n",
    "$$L = D - A$$\n",
    "\n",
    "where $A$ is an adjacency matrix and $D$ is a diagonal matrix with node degrees. Eigenvalues and eigenvectors of Laplacian can give us information about structure of a graph. Let us see a few simple examples.\n",
    "\n",
    "Write a function `eig_laplacian` that takes a graph and returns a tuple with 2 np.arrays: eigenvectors and eigenvalues of Laplacian. The both are ordered in ascending of eigenvalues. \n",
    "\n",
    "_Hints: any symmetric matrix has only real eigenvalues and eigenvectors. You can use `np.linalg.eigh` to calculate eigenvectors and eigenvalues in a symmetric matrix._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0c7c52f6045549d2bd274049aaf9804",
     "grade": false,
     "grade_id": "cell-75b0de6ccf68d1cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def eig_laplacian(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8821afac0ef10b04de33b4d46dcccc8",
     "grade": true,
     "grade_id": "cell-fd03c70f09c2d656",
     "locked": true,
     "points": 0.8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "emptyG = nx.empty_graph(10)\n",
    "vecs, vals = eig_laplacian(emptyG)\n",
    "assert vecs.sum() == 10\n",
    "assert vals.sum() == 0\n",
    "oneedgeG = nx.empty_graph(10)\n",
    "oneedgeG.add_edge(0, 1)\n",
    "vecs, vals = eig_laplacian(oneedgeG)\n",
    "assert abs(vecs.round(4)[0, -1]) == abs(vecs.round(4)[1, -1]) == 0.7071\n",
    "assert vals[0] < vals[-1]\n",
    "vecs, vals = eig_laplacian(nx.complete_graph(10))\n",
    "assert (vals == vals.real).sum() == vals.shape[0]\n",
    "assert (vecs == vecs.real).sum() == vals.shape[0]**2\n",
    "vecs, vals = eig_laplacian(ring_lattice(10, 2))\n",
    "assert adler32(vals.round(4)[-1]) == 6815825\n",
    "assert adler32(vals.round(4)[-2]) == 393479360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider some simple graphs and their Laplacian eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = []\n",
    "cases.append([emptyG, 'Empty graph', nx.draw_circular])\n",
    "cases.append([nx.complete_graph(10), 'Complete graph', nx.draw_circular])\n",
    "cases.append([ring_lattice(10, 2), 'Ring lattice', nx.draw_circular])\n",
    "cases.append([oneedgeG, 'Single edge', nx.draw_circular])\n",
    "cases.append([pair_graph(5), 'Pair of complete graphs', nx.draw_kamada_kawai])\n",
    "cases.append([triple_graph(5), 'Triple of complete graphs', nx.draw_kamada_kawai])\n",
    "\n",
    "plt.figure(figsize=(5*2, 5*6))\n",
    "i = 1\n",
    "for iterG, title, designer in cases:\n",
    "    plt.subplot(6, 2, i)\n",
    "    i += 1\n",
    "    designer(iterG, \n",
    "             node_color='tab:cyan', \n",
    "             edgecolors='black', \n",
    "             node_size=100)\n",
    "    plt.title(title)\n",
    "    plt.subplot(6, 2, i)\n",
    "    i += 1\n",
    "    vecs, vals = eig_laplacian(iterG)\n",
    "    plt.scatter(np.arange(1, len(iterG) + 1), vals)\n",
    "    plt.grid()\n",
    "    plt.xticks(np.arange(1, len(iterG) + 1))\n",
    "    plt.title('Ordered Laplacian eigenvalues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that a number of zero eigenvalues is a number of connected component. $\\lambda_2 = n$ in a complete graph. Also, the largest gap between eigenvalues indicates an optimal number of clusters. For example, the largest gap in a complete graph is between 1 and 2, then an optimal number of clusters is 1. Similarly, 2-3 gap is related to a pair graph, and 3-4 gap is related to a triple graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Spectral clustering (0.7 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering is a very powerful algorithm for community detection that minimize graph cuts. It is based on Laplacian eigenvectors, in particular a sign of the second smallest eigenvector determines the partition of a graph into two clusters. Consider the following artificial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles, truth_labels = datasets.make_circles(n_samples=300, factor=0.6, \n",
    "                                              noise=0.05, random_state=0)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(circles[:, 0], circles[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us isolate data points in center circle using spectral clustering. Any distance based dataset can be represented as a graph with edges between neighbors.\n",
    "\n",
    "Write a function `custom_graph` that takes a np.array with x-y data points and returns a connected graph. \n",
    "\n",
    "_Hint: try to apply `sklearn.neighbors.kneighbors_graph`._\n",
    "\n",
    "_Remark: you can introduce your own distance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49e30600afef1d7ade56b47134b59326",
     "grade": false,
     "grade_id": "cell-d40266c883f9c15b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def custom_graph(data):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32602c9aadb8c4041714b1d8692dec6a",
     "grade": true,
     "grade_id": "cell-64aedbe28b2b9b7d",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "circles, truth_labels = datasets.make_circles(n_samples=300, factor=0.6, \n",
    "                                              noise=0.05, random_state=0)\n",
    "circlesG = custom_graph(circles)\n",
    "assert circlesG.number_of_nodes() == 300\n",
    "assert nx.is_connected(circlesG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us draw values in second smallest eigenvector of Laplacian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs, vals = eig_laplacian(circlesG)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(np.arange(300), vecs[:, 1], s=10)\n",
    "plt.title('Second smallest eigenvector')\n",
    "plt.xlabel('Data point')\n",
    "plt.ylabel('Value')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write a function `spectral_two_clusters` that takes np.array with ordered eigenvectors and returns np.array with labels of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0bcce8de4c76511ba5efaf656dd6533",
     "grade": false,
     "grade_id": "cell-ca439ffb4eb0df3c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def spectral_two_clusters(vecs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad7d4cb81f371c53dc4fec58709edaa2",
     "grade": true,
     "grade_id": "cell-6b01f513f5380c76",
     "locked": true,
     "points": 0.4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "circles, truth_labels = datasets.make_circles(n_samples=300, factor=0.6, \n",
    "                                              noise=0.05, random_state=0)\n",
    "circlesG = custom_graph(circles)\n",
    "vecs, vals = eig_laplacian(circlesG)\n",
    "labels = spectral_two_clusters(vecs)\n",
    "\n",
    "assert abs(np.corrcoef(truth_labels, labels)[0, 1]) > 0.95\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(circles[:, 0], circles[:, 1], c=labels)\n",
    "plt.title('Correlation: {:.2f}'.format(abs(np.corrcoef(truth_labels, labels)[0, 1])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Remark: there are two directions of graph construction: selection pairs of nodes to connect to each other, and choosing the weights of created edges. Set `factor=0.7` in `datasets.make_circles` and test yourself — try to achive 0.9 correlation. Combine `sklearn.neighbors.kneighbors_graph` with `scipy.spatial.distance_matrix` or `sklearn.metrics.pairwise.rbf_kernel`. Details are [here](http://www2.imm.dtu.dk/projects/manifold/Papers/Laplacian.pdf)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Laplacian Eigenmaps (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous task, we saw how to split a graph into two parts. Let us consider a way to get more parts in the following graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadG = nx.disjoint_union_all([nx.complete_graph(5), \n",
    "                               nx.complete_graph(5),\n",
    "                               nx.complete_graph(5),\n",
    "                               nx.complete_graph(5)])\n",
    "quadG.add_edge(0, 5)\n",
    "quadG.add_edge(6, 10)\n",
    "quadG.add_edge(11, 16)\n",
    "quadG.add_edge(17, 1)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "nx.draw_kamada_kawai(\n",
    "    quadG, \n",
    "    node_color='white', \n",
    "    edgecolors='black', \n",
    "    node_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further splitting can be performed by different approaches. For example, we can repeat the clustering procedure on the both subgraphs separetely and choose a minimal graph cut and then repeat it again. Another way is to get Laplacian Eigenmaps and then apply KMeans. Let us consider how it works.\n",
    "\n",
    "1. Compute normalized Laplacian\n",
    "$$L = D^{-1/2}(D - A)D^{-1/2}$$\n",
    "2. Stack eigenvectors $L$ into the matrix $(x_1, x_2, \\dots)$ in ascending order of eigenvalues\n",
    "3. Multiply i-th row by $\\frac{1}{\\sqrt{d_i}}$ where $d_i$ is a node degree\n",
    "* $k$ vectors of the matrix starting from the second one is _Laplacian Eigenmaps (Spectral Embedding)_\n",
    "4. Put eigenmaps into KMeans\n",
    "5. Label nodes by fitted KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `norm_laplacian` that takes an adjacency matrix `A` and returns a tuple with 2 np.arrays. The first is a normalized Laplacian, the second is a degree sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8860c72d586b216b03d2028588fef600",
     "grade": false,
     "grade_id": "cell-835877a10376c87b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def norm_laplacian(A):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f686e3fd4c4155611dfed8d4a78e004b",
     "grade": true,
     "grade_id": "cell-0cf12928f9a5a348",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "A = nx.to_numpy_array(quadG)\n",
    "L, degree_seq = norm_laplacian(A)\n",
    "assert degree_seq.shape == (20, )\n",
    "assert L.shape == (20, 20)\n",
    "assert np.diagonal(L).sum() == 20\n",
    "assert round(L[:, 2].sum(), 4) == 0.0528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `spectral_embedding` that takes np.array with normalized Laplacian, np.arrays with degree sequence and returns np.array with Laplacian Eigenmaps. `n_components` is a number of vectors of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "beb974553ae260f809144771d43c94ae",
     "grade": false,
     "grade_id": "cell-3ff904d602d33bc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def spectral_embedding(L, degree_seq, n_components):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f623decfa8ae6a5aa7c9f7866ceeced5",
     "grade": true,
     "grade_id": "cell-798cee725cdd54c1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "embedding = spectral_embedding(L, degree_seq, 3)\n",
    "assert embedding.shape == (20, 3)\n",
    "assert embedding[:, 0].max() > 0\n",
    "assert embedding[:, 0].min() < 0\n",
    "assert embedding[:, 1].max() > 0\n",
    "assert embedding[:, 1].min() < 0\n",
    "assert (embedding[:, 0] > 0).sum() == 10\n",
    "assert (embedding[:, 1] > 0).sum() == 10\n",
    "assert (embedding[:, 2] > 0).sum() == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at a pairplot of the spectral embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7630fa781779881519d565799c2b8cc",
     "grade": false,
     "grade_id": "cell-682a760a2b70452c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def spectral_clustering(G, n_clusters, n_components):\n",
    "    A = nx.to_numpy_array(G)\n",
    "    L, degree_seq = norm_laplacian(A)\n",
    "    embedding = spectral_embedding(L, degree_seq, n_components)\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(embedding)\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "023ce19d069f0a0b7f69e3f545c4c923",
     "grade": true,
     "grade_id": "cell-0a5e4e1e0ff1e71b",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "embedding = spectral_embedding(L, degree_seq, 3)\n",
    "labels = spectral_clustering(quadG, 4, 3)\n",
    "assert np.all(labels[:5] == labels[0])\n",
    "assert np.all(labels[5:10] == labels[5])\n",
    "assert np.all(labels[10:15] == labels[10])\n",
    "assert np.all(labels[15:20] == labels[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = spectral_embedding(L, degree_seq, 3)\n",
    "labels = spectral_clustering(quadG, 4, 3)\n",
    "pair_data = pd.DataFrame(\n",
    "    np.hstack([embedding, labels[:, None]]), \n",
    "    columns=['x2', 'x3', 'x4', 'label'])\n",
    "pair_data.label = pair_data.label.astype('str')\n",
    "p = sns.pairplot(\n",
    "    pair_data,\n",
    "    hue='label',\n",
    "    diag_kind=None\n",
    ")\n",
    "p._legend.remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see four distinct clusters in the plots, that is why we use KMeans, but other clustering algorithms can also be applied here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "nx.draw_kamada_kawai(\n",
    "    quadG, \n",
    "    cmap=plt.cm.rainbow,\n",
    "    node_color=labels, \n",
    "    edgecolors='black', \n",
    "    node_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us see how spectral clustering works on the Les Miserables graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    G, \n",
    "    pos,\n",
    "    cmap=plt.cm.rainbow,\n",
    "    node_color=spectral_clustering(G, 6, 5), \n",
    "    node_size=100, \n",
    "    linewidths=1, \n",
    "    edgecolors='black'\n",
    ")\n",
    "nx.draw_networkx_edges(\n",
    "    G,\n",
    "    pos,\n",
    "    alpha=0.2,\n",
    "    edge_color='black'\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.legend(*nodes.legend_elements())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. Agglomerative clustering (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative clustering is an iterative procedure that unions similar clusters using a similarity matrix, but since we will run `sklearn.cluster.AgglomerativeClustering`, we need to pass a _distance_ matrix. So, first we need to choose a similarity measure and then convert it into a distance. Let us do it via SimRank measure that is defined as follows: _two objects are considered to be similar if they are referenced by similar objects_. Since SimRank takes values on the interval [0, 1], let us define a distance as\n",
    "\n",
    "$$\\text{Distance}= 1 - \\text{SimRank}$$\n",
    "\n",
    "Write a function `simrank_distance` that takes a graph and returns a distance matrix based on SimRank. Use `nx.simrank_similarity_numpy`. The distance matrix should be _absolutely_ symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a7a5a98d72e0f7fe6dd9abfb69ca828",
     "grade": false,
     "grade_id": "cell-3e562ed2f306eb66",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def simrank_distance(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6341496bdc9491f87617b126215fc200",
     "grade": true,
     "grade_id": "cell-48d3f5c5f233d84c",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "distance = simrank_distance(G)\n",
    "assert distance.shape == (77, 77)\n",
    "assert np.diagonal(distance).sum() == 0\n",
    "assert np.allclose(distance, distance.T, rtol=0, atol=0)\n",
    "assert distance[52, 68] <= distance[1, 19]\n",
    "assert distance[45, 29] <= distance[38, 46]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let us cluster nodes using `scipy.cluster.hierarchy.linkage`. The method takes distancies and returns an np.array with a matrix `Z` where every i-th row consists of\n",
    "* `Z[i, 0]` and `Z[i, 1]` are indexes of combined clusters\n",
    "* `Z[i, 2]` is the distance between combined clusters\n",
    "* `Z[i, 3]` is the number of observations in combined clusters\n",
    "\n",
    "Cluster with an index `n+i` is described in a i-th row of the matrix `Z`. Clusters with indexes less than `n+1` are initial nodes. The method `scipy.cluster.hierarchy.dendrogram` uses the matrix `Z` to plot a dendrogram. Let us look at a dendrogram of Les Miserables graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "linked = linkage(squareform(distance), 'complete')\n",
    "dendrogram(linked, labels=list(G.nodes), \n",
    "           leaf_font_size=12)\n",
    "plt.plot([0, 800], [0.89, 0.89], 'k--', c='tab:red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to select a horizontal line that gives us a partitioning of the graph. There are two approaches: select the number of clusters, and select the maximal distance between clusters. For example, if we select a horicontal line with maximal distance 0.89 (a red line on the plot) then the number of clusters will be 4.\n",
    "\n",
    "Write a function `agglomerative_clustering` that takes a distance matrix, maximal distance between clusters and returns an np.array with labels of clusters. Use `sklearn.cluster.AgglomerativeClustering` with complete linkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73dbc85d495a7b32523d7cc53961a725",
     "grade": false,
     "grade_id": "cell-0e16f6f2d6e0fbbf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def agglomerative_clustering(distance, max_distance):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0d21afa8c530e36e67c872e384b2a3c",
     "grade": true,
     "grade_id": "cell-a35a60118c1e0e83",
     "locked": true,
     "points": 0.8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(set(agglomerative_clustering(distance, 0.8))) == 17\n",
    "assert len(set(agglomerative_clustering(distance, 0.89))) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the graph with maximal distance 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = agglomerative_clustering(distance, 0.87)\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw_networkx_nodes(\n",
    "    G, \n",
    "    pos,\n",
    "    cmap=plt.cm.rainbow,\n",
    "    node_color=labels, \n",
    "    node_size=100, \n",
    "    linewidths=1, \n",
    "    edgecolors='black'\n",
    ")\n",
    "nx.draw_networkx_edges(\n",
    "    G,\n",
    "    pos,\n",
    "    alpha=0.2,\n",
    "    edge_color='black'\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from zlib import adler32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7. Louvain method (0.7 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Louvain method is one of the mostcited works in the community detection literature. It is a simple method to extract the community structure of large networks. This method is a heuristic method that is based on modularity optimization. Let us consider this method on a fractal graph that can represent some biological structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2931d7fb43bd324275afe5442a09626d",
     "grade": false,
     "grade_id": "cell-3e5a44deaa166ba6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fractal_graph(n, k, G):\n",
    "    if k == 0:\n",
    "        return G\n",
    "    for node in list(G.nodes):\n",
    "        newG = nx.complete_graph(n)\n",
    "        newG = nx.relabel_nodes(newG, {node:max(G.nodes)+node+1 for node in newG.nodes})\n",
    "        G = nx.union(G, newG)\n",
    "        for edge in G.edges(node):\n",
    "            G.add_edge(list(G.nodes)[-1], edge[1])\n",
    "        G.remove_node(node)\n",
    "    return fractal_graph(n, k-1, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fractalG = fractal_graph(n, 3, nx.complete_graph(n))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "frac_pos = nx.kamada_kawai_layout(fractalG)\n",
    "nx.draw_networkx_nodes(fractalG, frac_pos, node_color='white', \n",
    "                       edgecolors='black', node_size=100)\n",
    "nx.draw_networkx_edges(fractalG, frac_pos, alpha=0.3)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Louvain method is a greedy algorithm of modularity gain that is described as: \n",
    "\n",
    "Phase 1\n",
    "1. Put each node in its own community\n",
    "2. For every node, calculate modularity gain by removing it from its community and placing it in neighbor's community\n",
    "3. Put a node in the community with maximal modularity gain\n",
    "4. Repeat 2, 3 until modularity stops increasing\n",
    "\n",
    "Phase 2\n",
    "1. Merge communities into ”super nodes”\n",
    "2. Convert edges inside community into self loop, edges between communities into parallel edges\n",
    "\n",
    "Repeat phases 1, 2 until modularity stops increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd35e38367e1dd12940ebfb925ad9fec",
     "grade": false,
     "grade_id": "cell-21599c44baefbf81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def louvain_method(G):\n",
    "    \n",
    "    # Phase 1\n",
    "    communities = unfolded_communities(G)\n",
    "    labels = []\n",
    "    for node in G.nodes:\n",
    "        for i, c in enumerate(communities):\n",
    "            if node in c:\n",
    "                labels.append(i)\n",
    "    \n",
    "    # Phase 2\n",
    "    nextG = nx.empty_graph(len(communities), nx.MultiGraph)\n",
    "    for e in G.edges:\n",
    "        for i in range(len(communities)):\n",
    "            for j in range(len(communities)):\n",
    "                if e[0] in communities[i] and e[1] in communities[j]:\n",
    "                    nextG.add_edge(i, j)\n",
    "                    \n",
    "    # Shuffle colors for better visualization\n",
    "    palette = np.unique(labels)\n",
    "    key = np.random.permutation(palette)\n",
    "    labels = key[np.digitize(labels, palette, right=True)]\n",
    "    \n",
    "    return communities, labels, nextG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `unfolded_communities` that takes a graph, performs Phase 1 and returns np.array of communities with nodes. For example, if there are two communitites: the first is [1,2] and the second is [3,4,5] then the output will be [[1,2],[3,4,5]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4808b9f4a081116719c3e05a4bdc4ea6",
     "grade": false,
     "grade_id": "cell-fa81e37b363ca9d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def unfolded_communities(G):\n",
    "    # Proposed template:\n",
    "    communities = [[n] for n in G.nodes] # initial partition\n",
    "    prev_max_modularity = -np.inf\n",
    "    max_modularity = nx.algorithms.community.modularity(G, communities)\n",
    "    while max_modularity > prev_max_modularity:\n",
    "        prev_max_modularity = max_modularity\n",
    "        for node in np.random.permutation(G.nodes):\n",
    "            '''\n",
    "            1) Remove the node from the initial community.\n",
    "            2) Iterate all neighboring communities and move the node\n",
    "               into a community with the maximum modularity gain. If \n",
    "               there is no modularity gain, return the node into the \n",
    "               initial community.\n",
    "            '''\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "    return [c for c in communities if len(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47de079469a12021744b6bc4ed1727d0",
     "grade": true,
     "grade_id": "cell-fb6cb3a4447ea08c",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "fractalG = fractal_graph(n, 2, nx.complete_graph(n))\n",
    "iterG = fractalG.copy()\n",
    "communities, labels, nextG = louvain_method(iterG)\n",
    "\n",
    "assert len(set(labels)) == 16\n",
    "assert len(set(labels[52:56])) == 1\n",
    "assert len(set(labels[52:57])) == 2\n",
    "assert nextG.number_of_nodes() == 16\n",
    "assert round(np.linalg.det(nx.to_numpy_array(nextG)) * 1e-10, 4) == 136.5257"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see unfolding iterations. For every iteration we draw a graph where node color corresponds to the unfolded community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fractalG = fractal_graph(n, 3, nx.complete_graph(n))\n",
    "iterG = fractalG\n",
    "\n",
    "plt.figure(figsize=(7, 7*3))\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    communities, labels, nextG = louvain_method(iterG)\n",
    "    iter_pos = nx.kamada_kawai_layout(iterG)\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        iterG,\n",
    "        iter_pos,\n",
    "        cmap=plt.cm.rainbow,\n",
    "        node_color=labels,\n",
    "        edgecolors='black',\n",
    "        node_size=100)\n",
    "    nx.draw_networkx_edges(\n",
    "        iterG,\n",
    "        iter_pos,\n",
    "        node_size=100)\n",
    "    plt.axis('off')\n",
    "    plt.title(\n",
    "        '{} nodes, {} communities \\nModularity {:.2f}'.format(\n",
    "            len(iterG), len(communities), nx.community.modularity(iterG, communities)))\n",
    "    iterG = nextG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8. Ego-Splitting (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ego-Splitting is a framework for detecting clusters in complex networks which leverage the local structures known as ego-nets (i.e. the subgraph induced by the neighborhood of each node) to detect overlapping clusters. Ego-splittng is a highly scalable and flexible framework, with provable theoretical guarantees, that reduces the complex overlapping clustering problem to a simpler and more amenable non-overlapping (partitioning) problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the algorithm on this small graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjlist = [\n",
    "    'a b c e h g i',\n",
    "    'f b c e h g i',\n",
    "    'b e c',\n",
    "    'g i h',\n",
    "    'e c d',\n",
    "    'c d',\n",
    "    'i h j',\n",
    "    'h j',\n",
    "    'j d k',\n",
    "    'd k'\n",
    "]\n",
    "G = nx.parse_adjlist(adjlist)\n",
    "plt.figure(figsize=(5, 5))\n",
    "nx.draw_networkx(G, pos=nx.kamada_kawai_layout(G), \n",
    "                 node_size=400, node_color='lightgray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ego-splitting algorithm processes a graph $G = (V, E)$ and outputs a set of clusters $S$ as follows:\n",
    "1. For each node $u$ we use the local clustering algorithm to partition the ego-net of $u$.\n",
    "2. Create a set $V'$ of personas. Each node $u$ in $V$ will correspond to $t_u$ personas in $V'$.\n",
    "3. Add edges between personas.\n",
    "4. Apply the global clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/netspractice/network-science/main/assignment_communities_2/ego_splitting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "257c2920d75e96b8040650012f7138ae",
     "grade": false,
     "grade_id": "cell-c6992274eca070b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ego_splitting(graph):\n",
    "    ego_nets = generate_ego_nets(graph)\n",
    "    persona_graph = generate_persona_graph(ego_nets)\n",
    "    return persona_clustering(personaG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `generate_ego_nets` that takes a graph and returns a dictionary where keys are nodes and values are their ego-nets:\n",
    "\n",
    "`{'a': ego-net of the node a, 'b': ego-net of the node b, ...}`\n",
    "\n",
    "Ego-net *does not* include the ego-node.\n",
    "\n",
    "*Hint: use `nx.ego_graph`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39a8e88dfed4b923ddb5f9e0b40173f9",
     "grade": false,
     "grade_id": "cell-179c8ceed0004966",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_ego_nets(graph):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "957977561de6aff76eb8f297b93077f0",
     "grade": true,
     "grade_id": "cell-e9a468663cd92c49",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ego_nets = generate_ego_nets(G)\n",
    "assert set(ego_nets.keys()) == {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k'}\n",
    "assert set(ego_nets['d'].nodes) == {'c', 'e', 'j', 'k'}\n",
    "assert set(ego_nets['f'].nodes) == {'b', 'c', 'e', 'g', 'h', 'i'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(ego_nets['f'], pos=nx.kamada_kawai_layout(G), \n",
    "        node_color='lightgray', node_size=400)\n",
    "plt.title('Ego-net of the node f')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to split each ego-net using any clustering method. Let it be the simple connected component detection method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62cafb7a10d2aa3b7c6c8c8992b05d98",
     "grade": false,
     "grade_id": "cell-95005b99ee9acd1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ego_clustering(graph):\n",
    "    return [cc for cc in nx.connected_components(graph)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `generate_persona_graph` that takes an ego-net dictionary and returns a persona graph:\n",
    "1. Apply ego clustering for each ego-net.\n",
    "2. Add a replica of the ego-node into each cluster and link it to each member. If there is more than one cluster then the replica name is the node name + cluster index. For example, if the ego-net `a` has clusters `[b, c]` and `[d]` then we add edges `[a0, b]`, `[a0, c]` and `[a1, d]`. Otherwise, the replica name is the node name.\n",
    "3. Union all ego-nets into persona graph. Remove all nodes that has replicas. For example, if the graph has nodes `a`, `a0`, `a1`, then remove the node `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3d4d56a1f2f3b4173789e1810601c3c",
     "grade": false,
     "grade_id": "cell-91ff677c8729f5bf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_persona_graph(ego_nets):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "721173060c4fb4ba9584e47e79025472",
     "grade": true,
     "grade_id": "cell-964d19c73fa2da58",
     "locked": true,
     "points": 0.8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ego_nets = generate_ego_nets(G)\n",
    "personaG = generate_persona_graph(ego_nets)\n",
    "assert set(personaG.nodes) == {'i', 'f0', 'k', 'c', 'd0', 'a0', 'g', 'j0', 'e', 'h', 'd1', 'a1', 'j1', 'f1', 'b'}\n",
    "assert {i[0] for i in personaG.neighbors('k')} == {'d', 'j'}\n",
    "assert {i[0] for i in personaG.neighbors('g')} == {'a', 'f', 'h', 'i'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to apply any clustering algorithm for the persona graph. Let it again be the simple connected component detection algorithm. Also, here we remove the cluster indexes from node names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0f196d1ffe8b8a78d9993eaca0f75b6",
     "grade": false,
     "grade_id": "cell-e1224bd9ceeb3e42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def persona_clustering(graph):\n",
    "    communities = [cc for cc in nx.connected_components(graph)]\n",
    "    for c in communities:\n",
    "        for node in c:\n",
    "            c.remove(node)\n",
    "            c.add(node[0])\n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "c_colors = ['tab:orange', 'tab:blue', 'tab:green']\n",
    "for i, c in enumerate(ego_splitting(G)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    color = []\n",
    "    for node in G.nodes:\n",
    "        color.append(c_colors[i] if node in c else 'white')\n",
    "    nx.draw_networkx(G, pos=pos, node_color=color, \n",
    "                     edgecolors='black', node_size=400)\n",
    "    plt.axis('off')\n",
    "    plt.title('Colored nodes are in the community {}'.format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9. Label propogation (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label propogation method is based on the simple idea: every node is initialized with a unique label and at every step each node adopts the label that most of its neighbors currently have.\n",
    "\n",
    "Write a function `update_labels` that takes a graph, np.array with labels in order `graph.nodes` and returns new labels. Label of the node is the random label occurring with the highest frequency among neighbors at the previous step. The order in which all the n nodes in the network are updated at each iteration is chosen randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92d291709bc3f25a4d3f5cbbad7952c6",
     "grade": false,
     "grade_id": "cell-c5b24d3f2a43f307",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def update_labels(graph, labels):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf965f50f5b204f1f1c772afc2445e96",
     "grade": true,
     "grade_id": "cell-5ffe01098dbcbfbd",
     "locked": true,
     "points": 0.7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "labels = np.array(list(G.nodes)) # initial partition\n",
    "new_labels = update_labels(G, labels)\n",
    "assert new_labels.shape == (34, )\n",
    "assert len(set(new_labels)) < len(set(labels))\n",
    "G = nx.star_graph(4)\n",
    "labels = np.array(list(G.nodes)) # initial partition\n",
    "for _ in range(5):\n",
    "    labels = update_labels(G, labels)\n",
    "new_labels = update_labels(G, labels)\n",
    "assert len(set(new_labels - labels)) == 2\n",
    "assert np.sum(list(set(new_labels - labels))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_propogation(G, update_method, n=50):\n",
    "    pos=nx.kamada_kawai_layout(G)\n",
    "    labels = np.array(list(G.nodes))\n",
    "    for i in range(n):\n",
    "        clear_output(wait=True)\n",
    "        labels = update_method(G, labels)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        nx.draw_networkx_nodes(G, pos=pos, node_color=labels, cmap=plt.cm.tab10_r)\n",
    "        nx.draw_networkx_edges(G, pos=pos, alpha=0.2)\n",
    "        nx.draw_networkx_labels(G, pos=pos)\n",
    "        plt.axis('off')\n",
    "        plt.title('Iteration {}/{}'.format(i+1, n))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_propogation(nx.karate_club_graph(), update_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem however is that subgraphs in the network that are bi-partite or nearly bi-partite in structure lead to oscillations of labels.  This is especially true in cases where communities take the form of a star graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_propogation(nx.star_graph(30), update_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we need to use asynchronous updating where some neighbors have already been updated in the current iteration while some neighbors are not yet updated in the current iteration.\n",
    "\n",
    "Write a function `async_update_labels` that make asynchronous label updating. The order in which all the n nodes in the network are updated at each iteration is chosen randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "593d69d04a8d304277fdef1df4bba21d",
     "grade": false,
     "grade_id": "cell-416353e8934258da",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def async_update_labels(graph, labels):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af9d9340d087f6cd4703f2663676c3d3",
     "grade": true,
     "grade_id": "cell-c0271cbd0e8116aa",
     "locked": true,
     "points": 0.8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "labels = np.array(list(G.nodes)) # initial partition\n",
    "new_labels = async_update_labels(G, labels)\n",
    "assert new_labels.shape == (34, )\n",
    "assert len(set(new_labels)) < len(set(labels))\n",
    "G = nx.star_graph(4)\n",
    "labels = np.array(list(G.nodes)) # initial partition\n",
    "for _ in range(5):\n",
    "    labels = async_update_labels(G, labels)\n",
    "new_labels = async_update_labels(G, labels)\n",
    "assert np.all(new_labels - labels == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_propogation(nx.star_graph(30), async_update_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_propogation(nx.karate_club_graph(), async_update_labels, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
